{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI for Predictive Maintenance in Manufacturing\n",
    "\n",
    "**Copyright (c) 2026 Shrikara Kaudambady. All rights reserved.**\n",
    "\n",
    "This notebook demonstrates how to predict the Remaining Useful Life (RUL) of a machine using deep learning. We will use the NASA Turbofan Engine Degradation dataset to train a Long Short-Term Memory (LSTM) network. The model learns to predict the RUL based on a sequence of historical sensor readings from the engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Prepare the Data\n",
    "We will load the NASA Turbofan dataset (FD001). The dataset is already split into training and test sets. The training data runs until failure, while the test data stops at some point before failure. We first need to calculate the Remaining Useful Life (RUL) for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names for the dataset\n",
    "columns = ['engine_id', 'cycle', 'setting1', 'setting2', 'setting3'] + [f's{i}' for i in range(1, 22)]\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('https://raw.githubusercontent.com/dayjournal/CMAPSS/master/train_FD001.txt', sep='\\\\s+', header=None, names=columns)\n",
    "\n",
    "# Calculate RUL for the training data\n",
    "max_cycles = train_df.groupby('engine_id')['cycle'].max().reset_index()\n",
    "max_cycles.columns = ['engine_id', 'max_cycle']\n",
    "train_df = train_df.merge(max_cycles, on='engine_id', how='left')\n",
    "train_df['RUL'] = train_df['max_cycle'] - train_df['cycle']\n",
    "train_df = train_df.drop('max_cycle', axis=1)\n",
    "\n",
    "print(\"Training data prepared with RUL.\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Scaling and Sequencing\n",
    "We scale the sensor data to a [0, 1] range. Then, we transform the time-series data into 'windows' or sequences, which will be the input for our LSTM model. Each sequence will consist of 50 time steps of sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sensor columns and scale them\n",
    "sensor_cols = [f's{i}' for i in range(1, 22)]\n",
    "scaler = MinMaxScaler()\n",
    "train_df[sensor_cols] = scaler.fit_transform(train_df[sensor_cols])\n",
    "\n",
    "# Create sequences from the time-series data\n",
    "def create_sequences(df, sequence_length=50):\n",
    "    X, y = [], []\n",
    "    for engine_id in df['engine_id'].unique():\n",
    "        engine_df = df[df['engine_id'] == engine_id]\n",
    "        data = engine_df[sensor_cols].values\n",
    "        labels = engine_df['RUL'].values\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:i + sequence_length])\n",
    "            y.append(labels[i + sequence_length - 1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQUENCE_LENGTH = 50\n",
    "X_train, y_train = create_sequences(train_df, SEQUENCE_LENGTH)\n",
    "\n",
    "print(f\"Training data reshaped into sequences:\")\n",
    "print(f\"X_train shape: {X_train.shape}\") # (samples, timesteps, features)\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build and Train the LSTM Model\n",
    "We'll build a stacked LSTM model. Stacking LSTM layers can help the model learn more complex, hierarchical patterns in the time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1) # Output layer for RUL prediction\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining LSTM model...\")\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the Model on Test Data\n",
    "We now load the test data, process it in the same way as the training data, and evaluate our model's performance by predicting the RUL for the test engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and ground truth RUL values\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/dayjournal/CMAPSS/master/test_FD001.txt', sep='\\\\s+', header=None, names=columns)\n",
    "truth_df = pd.read_csv('https://raw.githubusercontent.com/dayjournal/CMAPSS/master/RUL_FD001.txt', sep='\\\\s+', header=None, names=['RUL'])\n",
    "\n",
    "# Scale the test data using the same scaler from training\n",
    "test_df[sensor_cols] = scaler.transform(test_df[sensor_cols])\n",
    "\n",
    "# For each engine in the test set, take the last 'sequence_length' cycles of data\n",
    "X_test = []\n",
    "for engine_id in test_df['engine_id'].unique():\n",
    "    engine_df = test_df[test_df['engine_id'] == engine_id]\n",
    "    data = engine_df[sensor_cols].values\n",
    "    # If an engine has less than 50 cycles, pad with zeros\n",
    "    if len(data) < SEQUENCE_LENGTH:\n",
    "        pad = np.zeros((SEQUENCE_LENGTH - len(data), data.shape[1]))\n",
    "        data = np.vstack([pad, data])\n",
    "    X_test.append(data[-SEQUENCE_LENGTH:])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = truth_df['RUL'].values\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Model Evaluation on Test Set ---\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
    "\n",
    "# Visualize predictions vs actuals\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red', lw=2)\n",
    "plt.xlabel(\"Actual RUL\")\n",
    "plt.ylabel(\"Predicted RUL\")\n",
    "plt.title(f\"Predictive Maintenance: Actual vs. Predicted RUL (RMSE: {rmse:.2f})\")\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}